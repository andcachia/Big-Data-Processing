{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciPi Spark Implementation - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV in Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joseph Azzopardi & Andrew Cachia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "from py2neo import Node\n",
    "from py2neo import Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to Neo4j API\n",
    "\n",
    "def neo4jConnect(IP, boltPort, username, pwd, httpPort):\n",
    "    bolturl = \"bolt://\" + IP + \":\" + boltPort\n",
    "    mygraph = Graph(bolturl, user=username, password=pwd, bolt=True, secure = False, http_port = httpPort)\n",
    "    #mygraph = Graph(\"bolt://40.114.206.146:7697\", user=\"neo4j\", password=\"joseph\", bolt=True, secure = False, http_port = 7484)\n",
    "    print (mygraph)\n",
    "                    \n",
    "    return mygraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to Neo4j Enterprise on Azure\n",
    "\n",
    "IP = \"neo4j-custom\" # IP Address of Neo4j Container\n",
    "boltPort = \"7687\"\n",
    "httpPort = 7474\n",
    "user = \"neo4j\"\n",
    "pwd  = \"test\"\n",
    "\n",
    "mygraph = neo4jConnect(IP, boltPort, user, pwd, httpPort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cquery1 = \"\"\"\n",
    "CREATE \n",
    "CONSTRAINT ON (n:Author) \n",
    "ASSERT n.authorid IS UNIQUE\n",
    "\"\"\"\n",
    "\n",
    "cquery2 = \"\"\"\n",
    "CREATE \n",
    "CONSTRAINT ON (n:Paper)\n",
    "ASSERT n.paperid IS UNIQUE\n",
    "\"\"\"\n",
    "\n",
    "cquery3 = \"\"\"\n",
    "CREATE \n",
    "CONSTRAINT ON (n:Publishers)\n",
    "ASSERT n.publisherid IS UNIQUE\n",
    "\"\"\"\n",
    "\n",
    "cquery4 = \"\"\"\n",
    "CREATE \n",
    "CONSTRAINT ON (n:ConfInstance) \n",
    "ASSERT n.confid IS UNIQUE\n",
    "\"\"\"\n",
    "\n",
    "cquery5 = \"\"\"\n",
    "CREATE \n",
    "CONSTRAINT ON (n:Journal)\n",
    "ASSERT n.journalid IS UNIQUE\n",
    "\"\"\"\n",
    "\n",
    "cquery6 = \"\"\"\n",
    "CREATE \n",
    "CONSTRAINT ON (n:Institution)\n",
    "ASSERT n.institutionid IS UNIQUE\n",
    "\"\"\"\n",
    "\n",
    "cquery7 = \"\"\"\n",
    "CREATE \n",
    "CONSTRAINT ON (n:Keyword) \n",
    "ASSERT n.name IS UNIQUE\n",
    "\"\"\"\n",
    "\n",
    "tx = mygraph.begin()\n",
    "tx.run (cquery1)\n",
    "tx.run (cquery2)\n",
    "tx.run (cquery3)\n",
    "tx.run (cquery4)\n",
    "tx.run (cquery5)\n",
    "tx.run (cquery6)\n",
    "tx.run (cquery7)\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author Nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample: 2797,Elena Frantova,3,28\n",
    "\n",
    "query_author_nodes = \"\"\"\n",
    "    USING PERIODIC COMMIT 1000\n",
    "    LOAD CSV FROM {csvfile}  AS line\n",
    "    MERGE (:Author { authorid: line[0], name: line[1] } )\n",
    "    \"\"\"\n",
    "#CREATE (:author { authorid: line[0], name: line[1], PaperCount: toInteger(line[2]), CiteCount: toInteger(line[3]) })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paper Nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample: 1979425243,Journal,Kinesin superfamily protein member 4 (KIF4) is localized to midzone and midbody in dividing cells,2004\n",
    "\n",
    "query_paper_nodes = \"\"\"\n",
    "        USING PERIODIC COMMIT 1000\n",
    "        LOAD CSV FROM {csvfile}  AS line\n",
    "        MERGE (:Paper{ paperid: line[0], doc_type:line[1], title:line[2], year: line[3] } )\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Publisher Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample: 8589934592,Western Economic Association International\n",
    "\n",
    "query_publisher_nodes = \"\"\"\n",
    "        USING PERIODIC COMMIT 1000\n",
    "        LOAD CSV FROM {csvfile}  AS line\n",
    "        MERGE (:Publishers { publisherid: line[0], name:line[1] })\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ConferenceInstance  Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample: 31227610,eurocon 2011,\"Lisbon, Portugal\"\n",
    "\n",
    "query_conferenceinstance_nodes = \"\"\"\n",
    "        USING PERIODIC COMMIT 1000\n",
    "        LOAD CSV FROM {csvfile}  AS line\n",
    "        MERGE (:ConfInstance { confid: line[0], name:line[1], location:line[2] })\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Journal Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample: 18204665,international journal of multiphase flow\n",
    "\n",
    "query_journal_nodes = \"\"\"\n",
    "        USING PERIODIC COMMIT 1000\n",
    "        LOAD CSV FROM {csvfile}  AS line\n",
    "        MERGE (:Journal { journalid: line[0], name:line[1] })\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Institutions Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample: 4,USSR Academy of Medical Sciences\n",
    "\n",
    "query_institution_nodes = \"\"\"\n",
    "        USING PERIODIC COMMIT 1000\n",
    "        LOAD CSV FROM {csvfile}  AS line\n",
    "        MERGE (:Institution { institutionid: line[0], name:line[1] })\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_keywords = \"\"\"\n",
    "        USING PERIODIC COMMIT 5000\n",
    "        LOAD CSV FROM {csvfile}  AS line\n",
    "        MERGE (paper:Paper{paperid:line[0]})\n",
    "        MERGE (keyword:Keyword{name:line[1]})\n",
    "        MERGE (paper)-[:Contains]->(keyword)\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationships Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Author-Author Relationships - Author Collaborations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample: \n",
    "\n",
    "#query_rel_auth_auth = \"\"\"\n",
    "#        USING PERIODIC COMMIT 1000\n",
    "#        LOAD CSV FROM {csvfile}  AS line\n",
    "#        MATCH (a:Author { authorid: line[0] })\n",
    "#        MATCH (b:Author { authorid: line[1] })\n",
    "#        CREATE (a)-[r:co_author { collaborations: line[2] }]->(b);\n",
    "#        \"\"\"\n",
    "\n",
    "query_rel_auth_auth = \"\"\"\n",
    "        USING PERIODIC COMMIT 1000\n",
    "        LOAD CSV FROM {csvfile}  AS line\n",
    "        MATCH (a:Author { authorid: line[0] })\n",
    "        MATCH (b:Author { authorid: line[1] })\n",
    "        CREATE (a)-[r:co_author]->(b);\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paper to Publisher Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample:  1968760085,1709396983808   (paperId, publisherId)\n",
    "\n",
    "query_rel_pub_paper = \"\"\"\n",
    "        USING PERIODIC COMMIT 1000\n",
    "        LOAD CSV FROM {csvfile}  AS line\n",
    "        MATCH (p:Paper {paperid: line[0]} )\n",
    "        MATCH (publisher:Publishers {publisherid: line[1]} )\n",
    "        CREATE (p)-[:published_by ]->(publisher);\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paper to ConfInstance Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample: 2140101510,2624888355   (paperId, conferenceInstanceId)\n",
    "\n",
    "query_rel_conf_paper = \"\"\"\n",
    "        USING PERIODIC COMMIT 1000\n",
    "        LOAD CSV FROM {csvfile}  AS line\n",
    "        MATCH (p:Paper {paperid: line[0]} )\n",
    "        MATCH (c:ConfInstance {confid: line[1]} )\n",
    "        CREATE (p)-[:conf_part_of]->(c);\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paper to Journal Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample: 2374592160,2764507941 (paperId, journalId)\n",
    "\n",
    "query_rel_journal_paper = \"\"\"\n",
    "        USING PERIODIC COMMIT 1000\n",
    "        LOAD CSV FROM {csvfile}  AS line\n",
    "        MATCH (p:Paper {paperid: line[0]} )\n",
    "        MATCH (j:Journal {journalid: line[1]} )\n",
    "        CREATE (p)-[:journal_part_of]->(j);\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paper-Author Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample author:    15,199142497,A      (paperid, authorid, relationship_type)\n",
    "# sample co-author: 15,680395887,CO_A   (paperid, authorid, relationship_type) \n",
    "\n",
    "\n",
    "query_rel_paper_author = \"\"\"\n",
    "        USING PERIODIC COMMIT 1000\n",
    "        LOAD CSV FROM {csvfile}  AS line\n",
    "        MATCH (p:Paper { paperid: line[0]})\n",
    "        MATCH (a:Author { authorid: line[1] })\n",
    "        CREATE (p)-[ :Authored{Type:line[2]} ]->(a);\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Author-Institution Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample: 2430849057,93   (distData.authorId, distData.institutionId)\n",
    "\n",
    "query_rel_author_inst = \"\"\"\n",
    "        USING PERIODIC COMMIT 1000\n",
    "        LOAD CSV FROM {csvfile}  AS line\n",
    "        MATCH (a:Author {authorid: line[0]} )\n",
    "        MATCH (i:Institution {institutionid: line[1]} )\n",
    "        CREATE (a)-[:member_of]->(i);\n",
    "        \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Csv To Neo4j Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importCsv(filename, query):\n",
    "    print(filename)\n",
    "    #csv_file_base = \"https://ics5114mag.blob.core.windows.net/parsed-csv-files/\"\n",
    "    csv_file_base = \"file:///\"\n",
    "    csvfile = csv_file_base + filename\n",
    "    \n",
    "    params = { \"csvfile\":csvfile }\n",
    "    mygraph.run(query, parameters=params )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Csv Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Azure\n",
    "#from azure.storage.blob import BlockBlobService\n",
    "#blob_service = BlockBlobService(account_name=\"ics5114mag\",account_key=\"ConHeKBYxAuTLZbVQsLM5ltqGmxv8aCrDoRylQGcus/P4yEqlzluItdl/5z8ZG3NXdyJ/f2Aye39ZMkHdGQwSg==\")\n",
    "#generator = blob_service.list_blobs(\"parsed-csv-files\")\n",
    "\n",
    "### Locally\n",
    "import os\n",
    "root_dir = \"/home/data\"\n",
    "generator = set()\n",
    "\n",
    "for dir_, _, files in os.walk(root_dir):\n",
    "    for file_name in files:\n",
    "        rel_dir = os.path.relpath(dir_, root_dir)\n",
    "        rel_file = os.path.join(rel_dir, file_name)\n",
    "        generator.add(rel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterCsv(directory, blob, query):\n",
    "    #filename = blob.name\n",
    "    filename = blob\n",
    "    if (filename.endswith(\".csv\")):\n",
    "        if (filename.startswith(\"results/\" + directory)):\n",
    "            importCsv(filename, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for blob in generator:\n",
    "        filterCsv(\"authors/\", blob, query_author_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for blob in generator:\n",
    "        filterCsv(\"papers/\", blob, query_paper_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for blob in generator:\n",
    "        filterCsv(\"publishers/\", blob, query_publisher_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for blob in generator:\n",
    "        filterCsv(\"conferenceinstance/\", blob, query_conferenceinstance_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for blob in generator:\n",
    "        filterCsv(\"journals/\", blob, query_journal_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for blob in generator:\n",
    "        filterCsv(\"institutions/\", blob, query_institution_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for blob in generator:\n",
    "        filterCsv(\"keywords/\", blob, query_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for blob in generator:\n",
    "        filterCsv(\"paper-publisher-rel/\", blob, query_rel_pub_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for blob in generator:\n",
    "        filterCsv(\"paper-confinstance-rel/\", blob, query_rel_conf_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for blob in generator:\n",
    "        filterCsv(\"paper-journal-rel/\", blob, query_rel_journal_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for blob in generator:\n",
    "        filterCsv(\"papers-author-rel/\", blob, query_rel_paper_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for blob in generator:\n",
    "        filterCsv(\"author-institution-rel/\", blob, query_rel_author_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for blob in generator:\n",
    "        filterCsv(\"author-author-rel/\", blob, query_rel_auth_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
